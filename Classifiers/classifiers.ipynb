{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "source": [
    "## Load and clean the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytable = MyPyTable()\n",
    "fName = os.path.join(\"InputData\", \"yelp_academic_dataset_business.json\")\n",
    "dataset = mytable.load_from_json_file(fName, 30000)\n",
    "dataset.remove_rows_with_missing_values()\n",
    "\n",
    "id_ = dataset.get_column('business_id')\n",
    "review_count = dataset.get_column('review_count')\n",
    "attributes = dataset.get_column('attributes')\n",
    "\n",
    "mytable2 = MyPyTable()\n",
    "dataset2 = mytable2.load_from_json_file('yelp_academic_dataset_tip.json', 30000)\n",
    "\n",
    "id_2 = dataset2.get_column('business_id')\n",
    "user_id = dataset2.get_column('user_id')\n",
    "text = dataset2.get_column('text')\n",
    "\n",
    "new_id = []\n",
    "new_user_id = []\n",
    "new_text = []\n",
    "for id in id_:\n",
    "    if id in id_2:\n",
    "        new_id.append(id)\n",
    "        index = id_2.index(id)\n",
    "        new_user_id.append(user_id[index])\n",
    "        new_text.append(text[index])\n",
    "\n",
    "new_id = new_id[:1500]\n",
    "new_user_id = new_user_id[:1500]\n",
    "new_text = new_text[:1500]\n",
    "\n",
    "new_rev_count = []\n",
    "new_attributes = []\n",
    "for id in new_id:\n",
    "    index = id_.index(id)\n",
    "    new_rev_count.append(review_count[index])\n",
    "    new_attributes.append(attributes[index])\n",
    "\n",
    "mytable3 = MyPyTable()\n",
    "dataset3 = mytable3.load_from_json_file('yelp_academic_dataset_user.json', 250000)\n",
    "\n",
    "user_id = dataset3.get_column('user_id')\n",
    "fans = dataset3.get_column('fans')\n",
    "compliment_plain = dataset3.get_column('compliment_plain')\n",
    "friends = dataset3.get_column('friends')\n",
    "useful = dataset3.get_column('useful')\n",
    "\n",
    "new_fans = []\n",
    "new_comp_plain = []\n",
    "new_friends = []\n",
    "new_useful = []\n",
    "for id in new_user_id: \n",
    "    if id in user_id:\n",
    "        index = user_id.index(id)\n",
    "        new_fans.append(fans[index])\n",
    "        new_comp_plain.append(compliment_plain[index])\n",
    "        new_friends.append(friends[index])\n",
    "        new_useful.append(useful[index])\n",
    "\n",
    "new_dataset = [[a, b, c, d, e, f, g] for a, b, c, d, e, f, g in zip(new_rev_count, new_attributes, new_text, new_fans, new_comp_plain, new_friends, new_useful)]\n",
    "\n",
    "columns = ['Review Count', 'Attributes', 'Review Length', 'Fans', 'Compliment Plain', 'Friends', 'Useful']\n",
    "final_dataset = MyPyTable(columns, new_dataset)\n",
    "\n",
    "final_dataset.replace_missing_values_with_column_average('Review Count')\n",
    "final_dataset.replace_missing_values_with_column_average('Attributes')\n",
    "final_dataset.replace_missing_values_with_column_average('Review Length')\n",
    "final_dataset.replace_missing_values_with_column_average('Fans')\n",
    "final_dataset.replace_missing_values_with_column_average('Compliment Plain')\n",
    "final_dataset.replace_missing_values_with_column_average('Friends')\n",
    "final_dataset.replace_missing_values_with_column_average('Useful')\n",
    "\n",
    "final_dataset.remove_rows_with_missing_values()\n",
    "\n",
    "final_dataset.get_shape()"
   ]
  },
  {
   "source": [
    "## Stratified k-fold Accuracy Check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#==================================\n",
    "#      Get stratified training    =\n",
    "#      and testing sets           =\n",
    "#==================================\n",
    "k = 10\n",
    "X, y = myutils.split_x_y_train(dataset.data)\n",
    "x_train, x_test, y_train, y_test = myevaluation.train_test_split(X, y, shuffle=True)\n",
    "\n",
    "# Get the training and testing folds\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X, y, k)\n",
    "\n",
    "# Get the traininga and testing sets from the folds\n",
    "x_train, y_train, x_test, y_test = myutils.get_values_from_folds(X, y, train_folds, test_folds)\n",
    "\n",
    "\n",
    "#==================================\n",
    "#      Naive Bayes Classifier     =\n",
    "#==================================\n",
    "myNB = MyNaiveBayesClassifier()\n",
    "myNB.fit(x_train, y_train)\n",
    "\n",
    "# Compare predicted with actual\n",
    "y_predict = myNB.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict)):\n",
    "    if (y_predict[i] == y_test[i]):\n",
    "        count = count + 1;\n",
    "\n",
    "# Calculate accuracy and error\n",
    "accuracy = count / len(y_predict)\n",
    "error = (len(y_predict) - count) / len(y_predict)\n",
    "\n",
    "print(\"Naive Bayes: accuracy =\", accuracy, \"error =\", error)\n",
    "\n",
    "#==================================\n",
    "#     Decision Tree Classifier    =\n",
    "#==================================\n",
    "myDT = MyDecisionTreeClassifier()\n",
    "myDT.fit(x_train, y_train)\n",
    "\n",
    "# Compare predicted with actual\n",
    "y_predict = myDT.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict)):\n",
    "    if (y_predict[i] == y_test[i]):\n",
    "        count = count + 1\n",
    "\n",
    "# Calculate accuracy and error\n",
    "accuracy = count / len(y_predict)\n",
    "error = (len(y_predict) - count) / len(y_predict)\n",
    "\n",
    "print(\"Decision Tree: accuracy =\", accuracy, \"error =\", error)\n",
    "\n",
    "#==================================\n",
    "#     Random Forest Classifier    =\n",
    "#==================================\n",
    "print(\"Random Forest: accuracy =\", \"tbd\", \"error =\", \"tbd\")"
   ]
  },
  {
   "source": [
    "## Confusion Matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the x values to perform the matrix over\n",
    "x = ['yes', 'no']\n",
    "\n",
    "actual = []\n",
    "nb_predicted = []\n",
    "for i in range(len(y_test)):\n",
    "    actual.append(y_test[i])\n",
    "    nb_predicted.append(y_predict[i])\n",
    "\n",
    "# Get the matrix from stratified\n",
    "nb_matrix = myevaluation.confusion_matrix(actual, nb_predicted, x)\n",
    "\n",
    "# Make the table header and calculate the statistics\n",
    "table_header = ['Survived', \"Yes\", \"No\", 'Total', 'Recognition (%)']\n",
    "complete_matrix = myutils.calc_matrix_stats(nb_matrix, True)\n",
    "\n",
    "print()\n",
    "print('Naive Bayes Result')\n",
    "myutils.print_tabulate(complete_matrix, table_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the x values to perform the matrix over\n",
    "x = ['yes', 'no']\n",
    "\n",
    "actual = []\n",
    "dt_predicted = []\n",
    "for i in range(len(y_test)):\n",
    "    actual.append(y_test[i])\n",
    "    dt_predicted.append(y_predict[i])\n",
    "\n",
    "# Get the matrix from stratified\n",
    "dt_matrix = myevaluation.confusion_matrix(actual, dt_predicted, x)\n",
    "\n",
    "# Make the table header and calculate the statistics\n",
    "table_header = ['Survived', \"Yes\", \"No\", 'Total', 'Recognition (%)']\n",
    "complete_matrix = myutils.calc_matrix_stats(dt_matrix, True)\n",
    "\n",
    "print()\n",
    "print('Decision Tree Result')\n",
    "myutils.print_tabulate(complete_matrix, table_header)"
   ]
  }
 ]
}