{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('conda': virtualenv)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyNaiveBayesClassifier, MyDecisionTreeClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation"
   ]
  },
  {
   "source": [
    "## Load and clean the data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Fans', 'Compliment Plain', 'Friends', 'Useful']\n"
     ]
    }
   ],
   "source": [
    "mytable = MyPyTable()\n",
    "fName = os.path.join(\"input_data\", \"trimmed_data.csv\")\n",
    "dataset = mytable.load_from_file(fName)\n",
    "dataset.remove_rows_with_missing_values()\n",
    "rows_to_delete = ['Review Count', 'Attributes', 'Review Length']\n",
    "myutils.remove_rows_from_data(rows_to_delete, dataset)\n",
    "print(dataset.column_names)\n",
    "myutils.get_friend_count(2, dataset)"
   ]
  },
  {
   "source": [
    "## Stratified k-fold Accuracy Check"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Naive Bayes: accuracy = 0.8598130841121495 error = 0.14018691588785046\n",
      "Decision Tree: accuracy = 0.16822429906542055 error = 0.8317757009345794\n"
     ]
    }
   ],
   "source": [
    "#==================================\n",
    "#      Get stratified training    =\n",
    "#      and testing sets           =\n",
    "#==================================\n",
    "k = 10\n",
    "X, y = myutils.split_x_y_train(dataset.data)\n",
    "x_train, x_test, y_train, y_test = myevaluation.train_test_split(X, y, shuffle=True)\n",
    "\n",
    "# Get the training and testing folds\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X, y, k)\n",
    "\n",
    "# Get the traininga and testing sets from the folds\n",
    "x_train, y_train, x_test, y_test = myutils.get_values_from_folds(X, y, train_folds, test_folds)\n",
    "\n",
    "\n",
    "#==================================\n",
    "#      Naive Bayes Classifier     =\n",
    "#==================================\n",
    "myNB = MyNaiveBayesClassifier()\n",
    "myNB.fit(x_train, y_train)\n",
    "\n",
    "# Compare predicted with actual\n",
    "y_predict = myNB.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict)):\n",
    "    binned_predict = myutils.get_useful_bin(y_predict[i])\n",
    "    binned_test = myutils.get_useful_bin(y_test[i])\n",
    "    if (binned_predict == binned_test):\n",
    "        count = count + 1;\n",
    "\n",
    "# Calculate accuracy and error\n",
    "accuracy = count / len(y_predict)\n",
    "error = (len(y_predict) - count) / len(y_predict)\n",
    "\n",
    "print(\"Naive Bayes: accuracy =\", accuracy, \"error =\", error)\n",
    "\n",
    "myDT = MyDecisionTreeClassifier()\n",
    "myDT.fit(x_train, y_train)\n",
    "\n",
    "y_predict = myDT.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict)):\n",
    "    binned_predict = myutils.get_useful_bin(y_predict[i])\n",
    "    binned_test = myutils.get_useful_bin(y_test[i])\n",
    "    if (binned_predict == binned_test):\n",
    "        count = count + 1;\n",
    "\n",
    "accuracy = count / len(y_predict)\n",
    "error = (len(y_predict) - count) / len(y_predict)\n",
    "\n",
    "print(\"Decision Tree: accuracy =\", accuracy, \"error =\", error)"
   ]
  },
  {
   "source": [
    "## Confusion Matrices"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nNaive Bayes\n========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n  Useful    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n       1  170   17    4    3    4    3    0    1    0     0      202              84.16\n       2  157   41    2    4    1    7    2    1    0     0      215              19.07\n       3  155   10    6    2    0    0    0    0    0     0      173               3.47\n       4  125    6    3    4    0    0    0    0    0     0      138               2.9\n       5  165   63   15   13    1    1    0    0    0     0      258               0.39\n       6   41   55   37   30   13    7    0    0    0     0      183               3.83\n       7   24   17    6   14   16    4    0    0    0     0       81               0\n       8   15   10   10   13   11    5    0    0    0     0       64               0\n       9   16    5    2    6   17    2    1    0    0     0       49               0\n      10   15   12   18    5   30   23    4    2    3    23      135              17.04\n========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "# Get the x values to perform the matrix over\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i + 1)\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "for i in range(len(y_test)):\n",
    "    actual.append(myutils.get_useful_bin(y_test[i]))\n",
    "    predicted.append(myutils.get_useful_bin(y_predict[i]))\n",
    "\n",
    "# Get the matrix from stratified\n",
    "matrix = myevaluation.confusion_matrix(actual, predicted, x)\n",
    "\n",
    "# Make the table header and calculate the statistics\n",
    "table_header = ['Useful', 1,2,3,4,5,6,7,8,9,10, 'Total', 'Recognition (%)']\n",
    "complete_matrix = myutils.calc_matrix_stats(matrix, False)\n",
    "\n",
    "print()\n",
    "print('Naive Bayes')\n",
    "myutils.print_tabulate(complete_matrix, table_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}