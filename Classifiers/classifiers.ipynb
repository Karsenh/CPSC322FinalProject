{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers Jupyter Notebook\n",
    "## Luke Mason & Karsen Hansen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some useful mysklearn package import statements and reloads\n",
    "import importlib\n",
    "\n",
    "import mysklearn.myutils\n",
    "importlib.reload(mysklearn.myutils)\n",
    "import mysklearn.myutils as myutils\n",
    "\n",
    "# uncomment once you paste your mypytable.py into mysklearn package\n",
    "import mysklearn.mypytable\n",
    "importlib.reload(mysklearn.mypytable)\n",
    "from mysklearn.mypytable import MyPyTable \n",
    "\n",
    "import mysklearn.myclassifiers\n",
    "importlib.reload(mysklearn.myclassifiers)\n",
    "from mysklearn.myclassifiers import MyNaiveBayesClassifier, MyDecisionTreeClassifier, MyRandomForestClassifier\n",
    "\n",
    "import mysklearn.myevaluation\n",
    "importlib.reload(mysklearn.myevaluation)\n",
    "import mysklearn.myevaluation as myevaluation\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Fans', 'Compliment Plain', 'Friends', 'Useful']\n",
      "[12.0, 30.0, 37.0, 179.0]\n"
     ]
    }
   ],
   "source": [
    "mytable = MyPyTable()\n",
    "fName = os.path.join(\"input_data\", \"trimmed_data.csv\")\n",
    "dataset = mytable.load_from_file(fName)\n",
    "dataset.remove_rows_with_missing_values()\n",
    "rows_to_delete = ['Review Count', 'Attributes', 'Review Length']\n",
    "myutils.remove_rows_from_data(rows_to_delete, dataset)\n",
    "myutils.get_friend_count(2, dataset)\n",
    "print(dataset.column_names)\n",
    "print(dataset.data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stratified k-fold Accuracy Check (Naive Bayes and Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes vs. Decision Tree Accuracy Comparison\n",
      "-----------------------------------\n",
      "Naive Bayes: accuracy = 0.8597194388777555 error = 0.1402805611222445\n",
      "Decision Tree: accuracy = 0.5424181696726786 error = 0.4575818303273213\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "#==================================\n",
    "#      Get stratified training    =\n",
    "#      and testing sets           =\n",
    "#==================================\n",
    "k = 10\n",
    "X, y = myutils.split_x_y_train(dataset.data)\n",
    "\n",
    "# Get the training and testing folds\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X, y, k)\n",
    "\n",
    "# Get the traininga and testing sets from the folds\n",
    "x_train, y_train, x_test, y_test = myutils.get_values_from_folds(X, y, train_folds, test_folds)\n",
    "\n",
    "\n",
    "print(\"Naive Bayes vs. Decision Tree Accuracy Comparison\")\n",
    "print(\"-----------------------------------\")\n",
    "#==================================\n",
    "#      Naive Bayes Classifier     =\n",
    "#==================================\n",
    "myNB = MyNaiveBayesClassifier()\n",
    "myNB.fit(x_train, y_train)\n",
    "\n",
    "# Compare predicted with actual\n",
    "y_predict_nb = myNB.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict_nb)):\n",
    "    binned_predict = myutils.get_useful_bin(y_predict_nb[i])\n",
    "    binned_test = myutils.get_useful_bin(y_test[i])\n",
    "    if (binned_predict == binned_test):\n",
    "        count = count + 1;\n",
    "\n",
    "# Calculate accuracy and error\n",
    "accuracy = count / len(y_predict_nb)\n",
    "error = (len(y_predict_nb) - count) / len(y_predict_nb)\n",
    "\n",
    "print(\"Naive Bayes: accuracy =\", accuracy, \"error =\", error)\n",
    "\n",
    "#==================================\n",
    "#     Decision Tree Classifier    =\n",
    "#==================================\n",
    "myDT = MyDecisionTreeClassifier()\n",
    "myDT_x_train = copy.deepcopy(x_train)\n",
    "myDT_y_train = copy.deepcopy(y_train)\n",
    "myDT.fit(myDT_x_train, myDT_y_train)\n",
    "\n",
    "y_predict_dt = myDT.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict_dt)):\n",
    "    binned_predict = myutils.get_useful_bin(y_predict_dt[i])\n",
    "    binned_test = myutils.get_useful_bin(y_test[i])\n",
    "    if (binned_predict == binned_test):\n",
    "        count = count + 1;\n",
    "\n",
    "accuracy = count / len(y_predict_dt)\n",
    "error = (len(y_predict_dt) - count) / len(y_predict_dt)\n",
    "\n",
    "print(\"Decision Tree: accuracy =\", accuracy, \"error =\", error)\n",
    "print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion Matrices (Naive Bayes & Decision Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Naive Bayes\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n",
      "  Useful    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n",
      "       1  167   21    9    4    1    0    0    0    0     0      202              82.67\n",
      "       2   63  130   14    5    3    0    0    0    0     0      215              60.47\n",
      "       3   23   18  120    8    4    0    0    0    0     0      173              69.36\n",
      "       4    8    7   12  108    3    0    0    0    0     0      138              78.26\n",
      "       5    0    2    3    2  251    0    0    0    0     0      258              97.29\n",
      "       6    0    0    0    0    0  183    0    0    0     0      183             100\n",
      "       7    0    0    0    0    0    0   81    0    0     0       81             100\n",
      "       8    0    0    0    0    0    0    0   64    0     0       64             100\n",
      "       9    0    0    0    0    0    0    0    0   49     0       49             100\n",
      "      10    0    0    0    0    0    0    0    0    0   134      134             100\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "# Get the x values to perform the matrix over\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i + 1)\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "for i in range(len(y_test)):\n",
    "    actual.append(myutils.get_useful_bin(y_test[i]))\n",
    "    predicted.append(myutils.get_useful_bin(y_predict_nb[i]))\n",
    "\n",
    "# Get the matrix from stratified\n",
    "matrix = myevaluation.confusion_matrix(actual, predicted, x)\n",
    "\n",
    "# Make the table header and calculate the statistics\n",
    "table_header = ['Useful', 1,2,3,4,5,6,7,8,9,10, 'Total', 'Recognition (%)']\n",
    "complete_matrix = myutils.calc_matrix_stats(matrix, False)\n",
    "\n",
    "print()\n",
    "print('Naive Bayes')\n",
    "myutils.print_tabulate(complete_matrix, table_header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Decision Tree\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n",
      "  Useful    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n",
      "       1  152   29    5    5    5    3    0    2    1     0      202              75.25\n",
      "       2   67   96   14   15   11    9    2    1    0     0      215              44.65\n",
      "       3   48   37   60   12   11    5    0    0    0     0      173              34.68\n",
      "       4   38   19   13   54   10    4    0    0    0     0      138              39.13\n",
      "       5   24   53   25   23  111   12    6    1    2     1      258              43.02\n",
      "       6   11   25   12   10   15   99    7    2    1     1      183              54.1\n",
      "       7    7    9    5    1    3    2   50    1    3     0       81              61.73\n",
      "       8    2    5    3    4    8    5    1   34    1     1       64              53.12\n",
      "       9    1    2    2    1    4    0    2    0   37     0       49              75.51\n",
      "      10    0    1    2    0    1    0    3    4    4   119      134              88.81\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "# Get the x values to perform the matrix over\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i + 1)\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "for i in range(len(y_test)):\n",
    "    actual.append(myutils.get_useful_bin(y_test[i]))\n",
    "    predicted.append(myutils.get_useful_bin(y_predict_dt[i]))\n",
    "\n",
    "# Get the matrix from stratified\n",
    "matrix = myevaluation.confusion_matrix(actual, predicted, x)\n",
    "\n",
    "# Make the table header and calculate the statistics\n",
    "table_header = ['Useful', 1,2,3,4,5,6,7,8,9,10, 'Total', 'Recognition (%)']\n",
    "complete_matrix = myutils.calc_matrix_stats(matrix, False)\n",
    "\n",
    "print()\n",
    "print('Decision Tree')\n",
    "myutils.print_tabulate(complete_matrix, table_header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree vs. Random Forest Trials to Tune Parameters\n",
      "-----------------------------------\n",
      "Decision Tree: accuracy = 0.5410821643286573 error = 0.4589178356713427\n",
      "-----------------------------------\n",
      "M = 10 N = 100 F = 3\n",
      "0 -- accuracy = 0.25656565656565655 error = 0.7434343434343434\n",
      "1 -- accuracy = 0.26666666666666666 error = 0.7333333333333333\n",
      "2 -- accuracy = 0.27070707070707073 error = 0.7292929292929293\n",
      "3 -- accuracy = 0.23636363636363636 error = 0.7636363636363637\n",
      "4 -- accuracy = 0.28888888888888886 error = 0.7111111111111111\n",
      "M = 10 N = 100 F = 2\n",
      "0 -- accuracy = 0.5191919191919192 error = 0.4808080808080808\n",
      "1 -- accuracy = 0.5575757575757576 error = 0.44242424242424244\n",
      "2 -- accuracy = 0.5555555555555556 error = 0.4444444444444444\n",
      "3 -- accuracy = 0.498989898989899 error = 0.501010101010101\n",
      "4 -- accuracy = 0.5737373737373738 error = 0.4262626262626263\n",
      "-----------------------------------\n",
      "M = 10 N = 500 F = 3\n",
      "0 -- accuracy = 0.25656565656565655 error = 0.7434343434343434\n",
      "1 -- accuracy = 0.2868686868686869 error = 0.7131313131313132\n",
      "2 -- accuracy = 0.25656565656565655 error = 0.7434343434343434\n",
      "3 -- accuracy = 0.26262626262626265 error = 0.7373737373737373\n",
      "4 -- accuracy = 0.22828282828282828 error = 0.7717171717171717\n",
      "M = 10 N = 500 F = 2\n",
      "0 -- accuracy = 0.6808080808080809 error = 0.3191919191919192\n",
      "1 -- accuracy = 0.6888888888888889 error = 0.3111111111111111\n",
      "2 -- accuracy = 0.6808080808080809 error = 0.3191919191919192\n",
      "3 -- accuracy = 0.696969696969697 error = 0.30303030303030304\n",
      "4 -- accuracy = 0.6747474747474748 error = 0.32525252525252524\n",
      "-----------------------------------\n",
      "M = 100 N = 500 F = 3\n",
      "0 -- accuracy = 0.24848484848484848 error = 0.7515151515151515\n",
      "1 -- accuracy = 0.2868686868686869 error = 0.7131313131313132\n",
      "2 -- accuracy = 0.25656565656565655 error = 0.7434343434343434\n",
      "3 -- accuracy = 0.2383838383838384 error = 0.7616161616161616\n",
      "4 -- accuracy = 0.24848484848484848 error = 0.7515151515151515\n",
      "M = 100 N = 500 F = 2\n",
      "0 -- accuracy = 0.7414141414141414 error = 0.2585858585858586\n",
      "1 -- accuracy = 0.7454545454545455 error = 0.2545454545454545\n",
      "2 -- accuracy = 0.7111111111111111 error = 0.28888888888888886\n",
      "3 -- accuracy = 0.7252525252525253 error = 0.27474747474747474\n",
      "4 -- accuracy = 0.7111111111111111 error = 0.28888888888888886\n",
      "-----------------------------------\n",
      "M = 25 N = 50 F = 3\n",
      "0 -- accuracy = 0.2828282828282828 error = 0.7171717171717171\n",
      "1 -- accuracy = 0.2585858585858586 error = 0.7414141414141414\n",
      "2 -- accuracy = 0.2383838383838384 error = 0.7616161616161616\n",
      "3 -- accuracy = 0.2686868686868687 error = 0.7313131313131314\n",
      "4 -- accuracy = 0.23030303030303031 error = 0.7696969696969697\n",
      "M = 25 N = 50 F = 2\n",
      "0 -- accuracy = 0.6828282828282828 error = 0.31717171717171716\n",
      "1 -- accuracy = 0.7212121212121212 error = 0.2787878787878788\n",
      "2 -- accuracy = 0.7333333333333333 error = 0.26666666666666666\n",
      "3 -- accuracy = 0.7353535353535353 error = 0.26464646464646463\n",
      "4 -- accuracy = 0.705050505050505 error = 0.29494949494949496\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "#==================================\n",
    "#      Get stratified training    =\n",
    "#      and testing sets           =\n",
    "#==================================\n",
    "\n",
    "X, y = myutils.split_x_y_train(dataset.data)\n",
    "x_train, x_test, y_train, y_test = myevaluation.train_test_split(X, y, shuffle=True)\n",
    "\n",
    "# Get the training and testing folds\n",
    "train_folds, test_folds = myevaluation.stratified_kfold_cross_validation(X, y, k)\n",
    "\n",
    "# Get the traininga and testing sets from the folds\n",
    "x_train, y_train, x_test, y_test = myutils.get_values_from_folds(X, y, train_folds, test_folds)\n",
    "\n",
    "#==================================\n",
    "#     Decision Tree Classifier    =\n",
    "#==================================\n",
    "myDT = MyDecisionTreeClassifier()\n",
    "myDT_x_train = copy.deepcopy(x_train)\n",
    "myDT_y_train = copy.deepcopy(y_train)\n",
    "myDT.fit(myDT_x_train, myDT_y_train)\n",
    "\n",
    "y_predict_dt = myDT.predict(x_test)\n",
    "count = 0\n",
    "for i in range(len(y_predict_dt)):\n",
    "    binned_predict = myutils.get_useful_bin(y_predict_dt[i])\n",
    "    binned_test = myutils.get_useful_bin(y_test[i])\n",
    "    if (binned_predict == binned_test):\n",
    "        count = count + 1;\n",
    "\n",
    "accuracy = count / len(y_predict_dt)\n",
    "error = (len(y_predict_dt) - count) / len(y_predict_dt)\n",
    "\n",
    "print(\"Decision Tree vs. Random Forest Trials to Tune Parameters\")\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "print(\"Decision Tree: accuracy =\", accuracy, \"error =\", error)\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "#==================================\n",
    "#     Random Forest Classifier    =\n",
    "#==================================\n",
    "\n",
    "#==================================\n",
    "#          M: 10, N: 100          =\n",
    "#==================================\n",
    "myutils.tune_parameters(10, 100, 3, dataset)\n",
    "\n",
    "#==================================\n",
    "#          M: 10, N: 100          =\n",
    "#==================================\n",
    "myutils.tune_parameters(10, 100, 2, dataset)\n",
    "\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "#==================================\n",
    "#          M: 10, N: 500          =\n",
    "#==================================\n",
    "myutils.tune_parameters(10, 500, 3, dataset)\n",
    "\n",
    "#==================================\n",
    "#          M: 10, N: 500          =\n",
    "#==================================\n",
    "myutils.tune_parameters(10, 500, 2, dataset)\n",
    "\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "#==================================\n",
    "#          M: 100, N: 500         =\n",
    "#==================================\n",
    "myutils.tune_parameters(100, 500, 3, dataset)\n",
    "\n",
    "#==================================\n",
    "#          M: 100, N: 500         =\n",
    "#==================================\n",
    "myutils.tune_parameters(100, 500, 2, dataset)\n",
    "\n",
    "\n",
    "print(\"-----------------------------------\")\n",
    "#==================================\n",
    "#          M: 25, N: 50           =\n",
    "#==================================\n",
    "myutils.tune_parameters(25, 50, 3, dataset)\n",
    "\n",
    "#==================================\n",
    "#          M: 25, N: 50           =\n",
    "#==================================\n",
    "myutils.tune_parameters(25, 50, 2, dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "It seems as though an M, high N, and F as 2 yields the best results, so let's try to take that to the extreme. We are going to set M=5, N=1000, and F=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Hypothesis Tests\n",
      "-----------------------------------\n",
      "Trial 0\n",
      "M = 5 N = 1000 F = 2\n",
      "0 -- accuracy = 0.5313131313131313 error = 0.4686868686868687\n",
      "1 -- accuracy = 0.5696969696969697 error = 0.4303030303030303\n",
      "2 -- accuracy = 0.6121212121212121 error = 0.3878787878787879\n",
      "3 -- accuracy = 0.6161616161616161 error = 0.3838383838383838\n",
      "4 -- accuracy = 0.5717171717171717 error = 0.42828282828282827\n",
      "-----------------------------------\n",
      "Trial 1\n",
      "M = 5 N = 1000 F = 2\n",
      "0 -- accuracy = 0.7191919191919192 error = 0.2808080808080808\n",
      "1 -- accuracy = 0.6606060606060606 error = 0.3393939393939394\n",
      "2 -- accuracy = 0.7131313131313132 error = 0.2868686868686869\n",
      "3 -- accuracy = 0.6747474747474748 error = 0.32525252525252524\n",
      "4 -- accuracy = 0.7535353535353535 error = 0.24646464646464647\n",
      "-----------------------------------\n",
      "Trial 2\n",
      "M = 5 N = 1000 F = 2\n",
      "0 -- accuracy = 0.35353535353535354 error = 0.6464646464646465\n",
      "1 -- accuracy = 0.34545454545454546 error = 0.6545454545454545\n",
      "2 -- accuracy = 0.3393939393939394 error = 0.6606060606060606\n",
      "3 -- accuracy = 0.3393939393939394 error = 0.6606060606060606\n",
      "4 -- accuracy = 0.37373737373737376 error = 0.6262626262626263\n",
      "-----------------------------------\n",
      "Trial 3\n",
      "M = 5 N = 1000 F = 2\n",
      "0 -- accuracy = 0.597979797979798 error = 0.402020202020202\n",
      "1 -- accuracy = 0.5696969696969697 error = 0.4303030303030303\n",
      "2 -- accuracy = 0.5777777777777777 error = 0.4222222222222222\n",
      "3 -- accuracy = 0.5494949494949495 error = 0.4505050505050505\n",
      "4 -- accuracy = 0.5656565656565656 error = 0.43434343434343436\n",
      "-----------------------------------\n",
      "Trial 4\n",
      "M = 5 N = 1000 F = 2\n",
      "0 -- accuracy = 0.3616161616161616 error = 0.6383838383838384\n",
      "1 -- accuracy = 0.3717171717171717 error = 0.6282828282828283\n",
      "2 -- accuracy = 0.3898989898989899 error = 0.6101010101010101\n",
      "3 -- accuracy = 0.34545454545454546 error = 0.6545454545454545\n",
      "4 -- accuracy = 0.34949494949494947 error = 0.6505050505050505\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Hypothesis Tests\")\n",
    "print(\"-----------------------------------\")\n",
    "for i in range(5):\n",
    "    print(\"Trial\", i)\n",
    "    myutils.tune_parameters(5, 1000, 2, dataset)\n",
    "    print(\"-----------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "The trials show mixed signals in terms of F's real impact. It seems there are attributes that fit the data better, and likely one that doesn't have the strongest relationship with classifying a useful review. That being said, the highest percentages have come from the above trials, so we will choose M = 5, N = 1000, and F = 2 for our parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest: accuracy = 0.7292929292929293 error = 2.294949494949495\n",
      "\n",
      "Random Forest\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n",
      "  Useful    1    2    3    4    5    6    7    8    9    10    Total    Recognition (%)\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n",
      "       1  320    8    2    0    0    0    0    0    0     0      330              96.97\n",
      "       2   33   13   16    3    7    0    0    0    0     0       72              18.06\n",
      "       3    3    6    7    0    1    0    0    0    0     6       23              30.43\n",
      "       4    1    2    5    5    3    0    0    0    0     1       17              29.41\n",
      "       5    0    3    3    2   10    1    0    0    0    11       30              33.33\n",
      "       6    0    1    0    0    2    3    0    0    0     7       13              23.08\n",
      "       7    0    0    0    0    0    1    0    0    0     1        2               0\n",
      "       8    0    0    0    0    0    0    0    0    0     4        4               0\n",
      "       9    0    0    0    0    0    0    0    0    0     1        1               0\n",
      "      10    0    0    0    0    0    0    0    0    0     3        3             100\n",
      "========  ===  ===  ===  ===  ===  ===  ===  ===  ===  ====  =======  =================\n"
     ]
    }
   ],
   "source": [
    "adjusted_dataset = myutils.select_random_attributes(2, dataset.data)\n",
    "\n",
    "X, y = myutils.split_x_y_train(adjusted_dataset)\n",
    "x_train, x_test, y_train, y_test = myevaluation.train_test_split(X, y, shuffle=True)\n",
    "\n",
    "remainder = []\n",
    "\n",
    "for j in range(len(x_train)):\n",
    "    row = x_train[j]\n",
    "    row.append(y_train[j])\n",
    "    remainder.append(row)\n",
    "    \n",
    "myRF = MyRandomForestClassifier()\n",
    "myRF.fit(remainder, 5, 1000)\n",
    "y_predict_rf = myRF.predict(x_test)\n",
    "\n",
    "count = 0\n",
    "for i in range(len(y_predict_rf)):\n",
    "    binned_predict = myutils.get_useful_bin(y_predict_rf[i])\n",
    "    binned_test = myutils.get_useful_bin(y_test[i])\n",
    "    if (binned_predict == binned_test):\n",
    "        count = count + 1;\n",
    "\n",
    "accuracy = count / len(y_predict_rf)\n",
    "error = (len(y_predict_dt) - count) / len(y_predict_rf)\n",
    "\n",
    "print(\"Random Forest: accuracy =\", accuracy, \"error =\", error)\n",
    "\n",
    "# Get the x values to perform the matrix over\n",
    "x = []\n",
    "for i in range(10):\n",
    "    x.append(i + 1)\n",
    "\n",
    "actual = []\n",
    "predicted = []\n",
    "for i in range(len(y_test)):\n",
    "    actual.append(myutils.get_useful_bin(y_test[i]))\n",
    "    predicted.append(myutils.get_useful_bin(y_predict_rf[i]))\n",
    "\n",
    "# Get the matrix from stratified\n",
    "matrix = myevaluation.confusion_matrix(actual, predicted, x)\n",
    "\n",
    "# Make the table header and calculate the statistics\n",
    "table_header = ['Useful', 1,2,3,4,5,6,7,8,9,10, 'Total', 'Recognition (%)']\n",
    "complete_matrix = myutils.calc_matrix_stats(matrix, False)\n",
    "\n",
    "print()\n",
    "print('Random Forest')\n",
    "myutils.print_tabulate(complete_matrix, table_header)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
